{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDDM analysis of EMBARC PRT data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Few changes here . . .\n",
    "\n",
    "import datetime, mmap,os,re # convention is to import things without \"as x\" first, on one line if possible\n",
    "import numpy as np # always useful\n",
    "import pandas as pd\n",
    "import seaborn as sns # uses matplotlib but more intuitive and streamline for what we do\n",
    "import matplotlib.pyplot as plt\n",
    "# below makes graphs open in the nb instead of in a separate window\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uname = !whoami\n",
    "uname = uname[0]\n",
    "#path2analysis = '/Users/' + uname + '/Work/Expts/PRT_DDM/Analysis/EMBARC_HDDM/' \n",
    "path2analysis = '/Users/' + uname + '/Work/Expts/EMBARC/' # also where git repo lives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/: File exists\n",
      "mkdir: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Michigan/UMTemp/: File exists\n",
      "mkdir: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/New_York/CUTemp/: File exists\n",
      "usage: cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file\n",
      "       cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ... target_directory\n",
      "mkdir: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Texas/TXTemp/: File exists\n"
     ]
    }
   ],
   "source": [
    "# This is a more compact way to do the job handled in the next few cells. Tuples are often useful and tuple unpacking \n",
    "# (e.g., state, abrev = val) is frequently helpful, esp. with pandas . . . \n",
    "\n",
    "for val in [('Massachusetts','MG'),('Michigan','UM'),('New_York','CU'),('Texas','TX')]:\n",
    "    state, abrev = val\n",
    "    base_dir = '/Users/' + uname + '/Work/Expts/EMBARC/Data/PRT/' + state + '/'\n",
    "    temp_dir = base_dir + abrev + 'Temp/'\n",
    "    old_files = base_dir + 'embarc_CU_' + abrev + '0*/done/sigdet_output*out'\n",
    "    flist = !ls {old_files}\n",
    "    \n",
    "    !mkdir {temp_dir}\n",
    "    \n",
    "    for old_fname in flist:\n",
    "        if abrev != 'CU':\n",
    "            sub = old_fname.split('_')[2]\n",
    "        else:\n",
    "            sub = old_fname.split('_')[3]\n",
    "        new_file = sub + '_out.txt'\n",
    "        new_fname = temp_dir + new_file\n",
    "        \n",
    "        !cp {old_fname} {new_fname} # Done this way you don't get error messages when there's no old file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I love the code you wrote to parse the files using regex, awesome!! A couple things to keep in mind that would\n",
    "# make it even better: (a) always include a docstring for your functions and (b) explicit is better than implicit\n",
    "# (see here: https://www.python.org/dev/peps/pep-0020/) So when you're choosing variable names, try to avoid things \n",
    "# like 'temp1' in favor of more descriptive (but still succinct) names (e.g., \"old_fname\"). Not always possible:)\n",
    "\n",
    "def SigDetParse(fname):\n",
    "    '''Open the file, use regex to pull out key vars, output a clean df.'''\n",
    "    \n",
    "    df = []\n",
    "    d = {}\n",
    "    ct = 0\n",
    "    \n",
    "    # Begin reading in data from the line including 'reward_due', as that's unlikely to occur anywhere earlier\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            if 'reward_due' in line:\n",
    "                for line in f:\n",
    "                    d[ct] = {'trial':line.split('\\t')[0],\n",
    "                             'length':line.split('\\t')[1],\n",
    "                             'time':line.split('\\t')[2], # tempting to change to RT but keep same for backwards compat\n",
    "                             'key_press':line.split('\\t')[3],\n",
    "                             'correct':line.split('\\t')[4],\n",
    "                             'did_reward':line.split('\\t')[5],\n",
    "                             'reward_due':line.split('\\t')[6],\n",
    "                             'rich_due':line.split('\\t')[7],\n",
    "                             'lean_due':line.split('\\t')[8],\n",
    "                             'outlier':line.split('\\t')[9].strip('\\n')}\n",
    "                    ct = ct + 1\n",
    "    df = pd.DataFrame.from_dict(d,orient='index')\n",
    "    \n",
    "\n",
    "    for val in [('rich_key','Rich key:'),('lean_key','Lean key:'), ('subject','Subject ID:'), ('date','Date:'), \n",
    "                ('bias','Bias:'), ('rich_stim','Rich stimulus:'), ('lean_stim','Lean stimulus:')]:\n",
    "        \n",
    "        var_name, pattern = val\n",
    "        df[var_name] = np.nan # Need some default values b/c some subjects have missing data        \n",
    "\n",
    "        if var_name != 'date':\n",
    "            var_def = re.compile(pattern + '[\\s]+([\\w]+)')\n",
    "        else:\n",
    "            var_def = re.compile(pattern + '[\\s]+([\\d]+/[\\d]+/[\\d]+)')\n",
    "        \n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                var_match = var_def.search(line)\n",
    "                if var_match:\n",
    "                    result = var_match.group(1)\n",
    "                    #checks if the subject ID is weird, prints it, and fixes it. For this data, all 3 digit sub ids\n",
    "                    #are fixed by adding a 0 to the beginning. \n",
    "                    if var_name =='subject' and len(result) !=4:\n",
    "                        print('Check sub ID: ' + fname)\n",
    "                        if len(result) == 3:\n",
    "                            df[var_name]='0'+ result\n",
    "                        if len(result) == 1:\n",
    "                            df[var_name] ='000' + result\n",
    "                    else:\n",
    "                        df[var_name] = result\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0020MGBP1R1_out.txt\n",
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0025MGBP2R1_out.txt\n",
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0027MGBP1R1_out.txt\n",
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0039MGBP2R1_out.txt\n",
      "Empty file: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0270MGBP1R1_out.txt\n",
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Michigan/UMTemp/UM0001UMBP1R1_out.txt\n",
      "Empty file: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Texas/TXTemp/TX0038MGBP3R1_out.txt\n",
      "Empty file: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Texas/TXTemp/TX0198TXBP2R1_out.txt\n"
     ]
    }
   ],
   "source": [
    "# Now you can just iterate over the files in each dir and use the code above to read each file into a ginorm df\n",
    "today = datetime.datetime.today().strftime(\"%m_%d_%Y\")\n",
    "\n",
    "dfs = []\n",
    "base_dir = '/Users/' + uname + '/Work/Expts/EMBARC/Data/PRT/'\n",
    "for val in [('Massachusetts','MG'),('Michigan','UM'),('New_York','CU'),('Texas','TX')]:\n",
    "    state, abrev = val\n",
    "    state_dir = base_dir + state + '/' + abrev + 'Temp'\n",
    "    flist = !ls {state_dir}\n",
    "    \n",
    "    for fname in flist:\n",
    "        curr_path = state_dir + '/' + fname \n",
    "        statinfo = os.stat(curr_path) # checking for empty files b/c I found one . . .\n",
    "        if statinfo.st_size == 0:\n",
    "            print ('Empty file: '+ curr_path)\n",
    "        else:\n",
    "            df = SigDetParse(curr_path)\n",
    "            df['site'] = abrev\n",
    "            df['ProjectSpecificID'] = df['site'] + df['subject']\n",
    "            dfs.append(df)\n",
    "out = pd.concat(dfs)\n",
    "out = out[['ProjectSpecificID','site','subject','date','bias','rich_stim','lean_stim','rich_key','lean_key',\n",
    "           'trial','length','time','key_press','correct','did_reward','reward_due','rich_due','lean_due','outlier']]\n",
    "out.to_csv(path2analysis + 'embarc_PRT_one_sess_' + today + ' .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0020MGBP1R1_out.txt\n",
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0027MGBP1R1_out.txt\n",
      "Empty file: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Massachusetts/MGTemp/MG0270MGBP1R1_out.txt\n",
      "Check sub ID: /Users/mlm2/Work/Expts/EMBARC/Data/PRT/Michigan/UMTemp/UM0001UMBP1R1_out.txt\n"
     ]
    }
   ],
   "source": [
    "# I will work on a way to combine this with the above kernel, but for now this makes a separate file \n",
    "# that only contains data from the first session (since some people did multiple sessions)\n",
    "today = datetime.datetime.today().strftime(\"%m_%d_%Y\")\n",
    "\n",
    "dfs = []\n",
    "base_dir = '/Users/' + uname + '/Work/Expts/EMBARC/Data/PRT/'\n",
    "for val in [('Massachusetts','MG'),('Michigan','UM'),('New_York','CU'),('Texas','TX')]:\n",
    "    state, abrev = val\n",
    "    state_dir = base_dir + state + '/' + abrev + 'Temp'\n",
    "    state_one_sess = base_dir + state + '/' + abrev + 'Temp/*P1*'\n",
    "    flist = !ls {state_dir}\n",
    "    flist_one_sess = !ls {state_one_sess}\n",
    "    \n",
    "    for fname in flist_one_sess:\n",
    "        curr_path = fname   \n",
    "        statinfo = os.stat(curr_path) # checking for empty files b/c I found one . . .\n",
    "        if statinfo.st_size == 0:\n",
    "            print ('Empty file: '+ curr_path)\n",
    "        else:\n",
    "            df = SigDetParse(curr_path)\n",
    "            df['site'] = abrev\n",
    "            df['ProjectSpecificID'] = df['site'] + df['subject']\n",
    "            dfs.append(df)\n",
    "out = pd.concat(dfs)\n",
    "out = out[['ProjectSpecificID','site','subject','date','bias','rich_stim','lean_stim','rich_key','lean_key',\n",
    "           'trial','length','time','key_press','correct','did_reward','reward_due','rich_due','lean_due','outlier']]\n",
    "out.to_csv(path2analysis + 'embarc_PRT_one_sess_' + today + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectSpecificID</th>\n",
       "      <th>site</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>bias</th>\n",
       "      <th>rich_stim</th>\n",
       "      <th>lean_stim</th>\n",
       "      <th>rich_key</th>\n",
       "      <th>lean_key</th>\n",
       "      <th>trial</th>\n",
       "      <th>length</th>\n",
       "      <th>time</th>\n",
       "      <th>key_press</th>\n",
       "      <th>correct</th>\n",
       "      <th>did_reward</th>\n",
       "      <th>reward_due</th>\n",
       "      <th>rich_due</th>\n",
       "      <th>lean_due</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MG0001</td>\n",
       "      <td>MG</td>\n",
       "      <td>0001</td>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>683</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MG0001</td>\n",
       "      <td>MG</td>\n",
       "      <td>0001</td>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "      <td>long</td>\n",
       "      <td>1307</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG0001</td>\n",
       "      <td>MG</td>\n",
       "      <td>0001</td>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>short</td>\n",
       "      <td>577</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG0001</td>\n",
       "      <td>MG</td>\n",
       "      <td>0001</td>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>4</td>\n",
       "      <td>long</td>\n",
       "      <td>677</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MG0001</td>\n",
       "      <td>MG</td>\n",
       "      <td>0001</td>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "      <td>short</td>\n",
       "      <td>724</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProjectSpecificID site subject        date   bias rich_stim lean_stim  \\\n",
       "0            MG0001   MG    0001  12/14/2011  short     short      long   \n",
       "1            MG0001   MG    0001  12/14/2011  short     short      long   \n",
       "2            MG0001   MG    0001  12/14/2011  short     short      long   \n",
       "3            MG0001   MG    0001  12/14/2011  short     short      long   \n",
       "4            MG0001   MG    0001  12/14/2011  short     short      long   \n",
       "\n",
       "  rich_key lean_key trial length  time key_press correct did_reward  \\\n",
       "0        c        m     1  short   683         c       1          0   \n",
       "1        c        m     2   long  1307         c       0          0   \n",
       "2        c        m     3  short   577         c       1          1   \n",
       "3        c        m     4   long   677         m       1          1   \n",
       "4        c        m     5  short   724         c       1          0   \n",
       "\n",
       "  reward_due rich_due lean_due outlier  \n",
       "0          0        0        0       0  \n",
       "1          1        0        1       1  \n",
       "2          1        0        1       0  \n",
       "3          1        0        0       0  \n",
       "4          0        0        0       0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectSpecificID</th>\n",
       "      <th>site</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>bias</th>\n",
       "      <th>rich_stim</th>\n",
       "      <th>lean_stim</th>\n",
       "      <th>rich_key</th>\n",
       "      <th>lean_key</th>\n",
       "      <th>trial</th>\n",
       "      <th>length</th>\n",
       "      <th>time</th>\n",
       "      <th>key_press</th>\n",
       "      <th>correct</th>\n",
       "      <th>did_reward</th>\n",
       "      <th>reward_due</th>\n",
       "      <th>rich_due</th>\n",
       "      <th>lean_due</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>TX0204</td>\n",
       "      <td>TX</td>\n",
       "      <td>0204</td>\n",
       "      <td>10/12/2015</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>196</td>\n",
       "      <td>short</td>\n",
       "      <td>686</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>TX0204</td>\n",
       "      <td>TX</td>\n",
       "      <td>0204</td>\n",
       "      <td>10/12/2015</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>197</td>\n",
       "      <td>long</td>\n",
       "      <td>365</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>TX0204</td>\n",
       "      <td>TX</td>\n",
       "      <td>0204</td>\n",
       "      <td>10/12/2015</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>198</td>\n",
       "      <td>long</td>\n",
       "      <td>846</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>TX0204</td>\n",
       "      <td>TX</td>\n",
       "      <td>0204</td>\n",
       "      <td>10/12/2015</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>199</td>\n",
       "      <td>short</td>\n",
       "      <td>414</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>TX0204</td>\n",
       "      <td>TX</td>\n",
       "      <td>0204</td>\n",
       "      <td>10/12/2015</td>\n",
       "      <td>short</td>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>200</td>\n",
       "      <td>short</td>\n",
       "      <td>1083</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProjectSpecificID site subject        date   bias rich_stim lean_stim  \\\n",
       "195            TX0204   TX    0204  10/12/2015  short     short      long   \n",
       "196            TX0204   TX    0204  10/12/2015  short     short      long   \n",
       "197            TX0204   TX    0204  10/12/2015  short     short      long   \n",
       "198            TX0204   TX    0204  10/12/2015  short     short      long   \n",
       "199            TX0204   TX    0204  10/12/2015  short     short      long   \n",
       "\n",
       "    rich_key lean_key trial length  time key_press correct did_reward  \\\n",
       "195        c        m   196  short   686         m       0          0   \n",
       "196        c        m   197   long   365         m       1          1   \n",
       "197        c        m   198   long   846         m       1          0   \n",
       "198        c        m   199  short   414         c       1          1   \n",
       "199        c        m   200  short  1083         c       1          0   \n",
       "\n",
       "    reward_due rich_due lean_due outlier  \n",
       "195          1        1        0       0  \n",
       "196          1        1        0       0  \n",
       "197          0        1        0       0  \n",
       "198          1        0        0       0  \n",
       "199          0        0        0       0  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79770"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks right . . . \n",
    "out.ProjectSpecificID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add_Group.ipynb                      embarc_PRT_11_15_2016 .csv\r\n",
      "\u001b[34mData\u001b[m\u001b[m/                                embarc_PRT_one_sess11_15_2016 .csv\r\n",
      "Old_PRT_Prettier.ipynb               embarc_PRT_one_sess11_15_2016.csv\r\n",
      "PRT_DDM-Copy1.ipynb                  embarc_PRT_one_sess_11_15_2016 .csv\r\n",
      "PRT_DDM.ipynb                        embarc_PRT_one_sess_11_15_2016.csv\r\n",
      "PRT_Prettier.ipynb                   groups.csv\r\n",
      "README.md                            why\r\n",
      "eh.csv                               why.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Note that the CSV has been written out\n",
    "%ls {path2analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008',\n",
       "       '0018', '0020', '0021', '0025', '0027', '0028', '0030', '0032',\n",
       "       '0039', '0040', '0051', '0060', '0064', '0066', '0069', '0070',\n",
       "       '0074', '0076', '0081', '0086', '0101', '0104', '0106', '0112',\n",
       "       '0116', '0117', '0120', '0125', '0126', '0135', '0137', '0138',\n",
       "       '0142', '0152', '0155', '0157', '0158', '0161', '0164', '0168',\n",
       "       '0172', '0180', '0182', '0185', '0187', '0198', '0202', '0206',\n",
       "       '0207', '0209', '0213', '0214', '0218', '0220', '0222', '0228',\n",
       "       '0230', '0231', '0238', '0239', '0242', '0243', '0246', '0248',\n",
       "       '0251', '0252', '0253', '0256', '0257', '0259', '0261', '0269',\n",
       "       '0270', '0009', '0011', '0012', '0014', '0015', '0016', '0017',\n",
       "       '0023', '0024', '0029', '0031', '0033', '0034', '0035', '0036',\n",
       "       '0037', '0038', '0042', '0046', '0047', '0048', '0049', '0050',\n",
       "       '0052', '0056', '0058', '0065', '0073', '0077', '0078', '0079',\n",
       "       '0080', '0082', '0083', '0085', '0088', '0089', '0090', '0091',\n",
       "       '0092', '0093', '0096', '0097', '0100', '0102', '0103', '0107',\n",
       "       '0108', '0110', '0111', '0113', '0114', '0115', '0118', '0119',\n",
       "       '0121', '0010', '0013', '0022', '0026', '0041', '0053', '0055',\n",
       "       '0057', '0059', '0061', '0062', '0063', '0067', '0068', '0071',\n",
       "       '0072', '0075', '0084', '0087', '0094', '0095', '0099', '0105',\n",
       "       '0127', '0128', '0129', '0130', '0131', '0132', '0133', '0134',\n",
       "       '0019', '0043', '0045', '0122', '0123', '0124', '0136', '0139',\n",
       "       '0140', '0141', '0145', '0147', '0148', '0149', '0151', '0153',\n",
       "       '0156', '0159', '0162', '0165', '0169', '0173', '0174', '0175',\n",
       "       '0177', '0178', '0179', '0184', '0188', '0189', '0193', '0194',\n",
       "       '0195', '0204'], dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that change fixed the wacky numbers, looks like it did\n",
    "out.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mlm2/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3,104,109,113,117,118,119,122,123,127,133,134,135,136,138,141,142,219,221,227,229,231,232,233,234,235,236,237,238,239,240,241,242,243,244,250,251,252,253,258,260,262,264,266,268,276,280,283,285,287,290,293,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,336,338,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,392,396,408,410,411,417,418,419,421,422,423,460,462,464,466,468,470,472,474,476,478,480,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,590,800,801,812,813,814,823,861) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Combines the group data (groups.csv) with the task data, is really big, prob best to not work with too much\n",
    "df_task = pd.read_csv('embarc_PRT_one_sess_11_15_2016.csv')\n",
    "df_group = pd.read_csv('groups.csv',encoding=\"latin-1\")\n",
    "df_all = df_task.merge(df_group, how='outer')\n",
    "\n",
    "df_all.to_csv('embarc_combined_' + today+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
